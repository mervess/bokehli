{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a16eeb96",
   "metadata": {},
   "source": [
    "# Initial Handling and Shaping of Data via _PySpark_ âœ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702abb6",
   "metadata": {},
   "source": [
    "## The PySpark Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e71bd",
   "metadata": {},
   "source": [
    "Start the PySpark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a6092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName( 'BabyNamesZurich' ).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59f0f4",
   "metadata": {},
   "source": [
    "## The PySpark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3d2d2",
   "metadata": {},
   "source": [
    "Read from the CSV file and put the data into a PySpark DataFrame:\n",
    "\n",
    "_(from now on the DataFrame will be called as \"df\")_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22cf591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+--------+----------+\n",
      "|StichtagDatJahr| Vorname| SexLang|AnzGebuWir|\n",
      "+---------------+--------+--------+----------+\n",
      "|           1993|  Abarna|weiblich|         1|\n",
      "|           1993| Abetare|weiblich|         1|\n",
      "|           1993|    Abir|weiblich|         1|\n",
      "|           1993| Abirami|weiblich|         1|\n",
      "|           1993|Adelaide|weiblich|         1|\n",
      "+---------------+--------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_file = '../datasets/baby_vornamen.csv'\n",
    "df = spark.read.csv( data_file, header=True, inferSchema=True )\n",
    "# Show first 5 lines of data\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a25680",
   "metadata": {},
   "source": [
    "### Change the scene of the data a little bit ðŸ”®ðŸª„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a79074",
   "metadata": {},
   "source": [
    "Changing the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4788f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed( 'StichtagDatJahr', 'year' ) \\\n",
    "        .withColumnRenamed( 'Vorname', 'name' ) \\\n",
    "        .withColumnRenamed( 'SexLang', 'sex' ) \\\n",
    "        .withColumnRenamed( 'AnzGebuWir', 'freq' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea189b4",
   "metadata": {},
   "source": [
    "Change the column value of 'sex':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b255ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = df.withColumn( 'sex', \n",
    "         when( df.sex.ilike( 'weiblich' ), 'F' ) \\\n",
    "        .when( df.sex.ilike( 'mÃ¤nnlich' ), 'M' )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7bfe6",
   "metadata": {},
   "source": [
    "#### A column value can also be changed via function _regexp_replace_ in PySpark.\n",
    "\n",
    "Below is an example use-case.\n",
    "\n",
    "```python\n",
    "\n",
    "from pyspark.sql.functions import when, regexp_replace\n",
    "\n",
    "df = df.withColumn( 'sex', \n",
    "         when( df.sex.ilike( 'weiblich' ), regexp_replace( df.sex, 'weiblich', 'F' ) ) \\\n",
    "        .when( df.sex.ilike( 'mÃ¤nnlich' ), regexp_replace( df.sex, 'mÃ¤nnlich', 'M' ) )\n",
    ")\n",
    "\n",
    "# == OR ==\n",
    "\n",
    "df = df.withColumn( 'sex', \n",
    "         regexp_replace( df.sex, 'weiblich', 'F' )\n",
    ")\n",
    "```\n",
    "\n",
    "However, _regexp_replace_ is rather a better fit for partial word replacements.\n",
    "\n",
    "Because the whole value of the data is replaced, it is not necessary to use it this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65219dab",
   "metadata": {},
   "source": [
    "#### Let's see the updated data  ðŸ‘€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb702d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+----+\n",
      "|year|    name|sex|freq|\n",
      "+----+--------+---+----+\n",
      "|1993|  Abarna|  F|   1|\n",
      "|1993| Abetare|  F|   1|\n",
      "|1993|    Abir|  F|   1|\n",
      "|1993| Abirami|  F|   1|\n",
      "|1993|Adelaide|  F|   1|\n",
      "+----+--------+---+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- freq: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6757fd",
   "metadata": {},
   "source": [
    "## Hello SQL ðŸ‘‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84776d6b",
   "metadata": {},
   "source": [
    "How to turn a PySpark df into a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82cbfc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView( 'NEWBORNS' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315dc2b0",
   "metadata": {},
   "source": [
    "Viewing the newly created table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ef8ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         | newborns|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql( \"SHOW TABLES\" ).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newborns_spark",
   "language": "python",
   "name": "newborns_spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
