{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4efb9a",
   "metadata": {},
   "source": [
    "# SQL in Spark: The Same Vibes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecefe3be-adb4-4dc5-8769-70388dfe00d0",
   "metadata": {},
   "source": [
    "The topic of this notebook is how to write the same code via PySpark's SQL module vs. library functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b4d8e-2e21-4999-b979-e08f695fd2d0",
   "metadata": {},
   "source": [
    "In the following parts, each time, firstly SQL query comes, then library function calling follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881076e-8f41-4d2d-8354-fa0f31438d28",
   "metadata": {},
   "source": [
    "ðŸ”· This notebook should be run after _initialisation_nb_ notebook via the same kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09bbd5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Viewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "417d9fe0-dc7a-4609-8912-09fb892e974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+----+\n",
      "|year|    name|sex|freq|\n",
      "+----+--------+---+----+\n",
      "|1993|  Abarna|  F|   1|\n",
      "|1993| Abetare|  F|   1|\n",
      "|1993|    Abir|  F|   1|\n",
      "|1993| Abirami|  F|   1|\n",
      "|1993|Adelaide|  F|   1|\n",
      "+----+--------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "'''\n",
    "SELECT *\n",
    "FROM\n",
    "    newborns\n",
    "LIMIT 5\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5c5d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+----+\n",
      "|year|    name|sex|freq|\n",
      "+----+--------+---+----+\n",
      "|1993|  Abarna|  F|   1|\n",
      "|1993| Abetare|  F|   1|\n",
      "|1993|    Abir|  F|   1|\n",
      "|1993| Abirami|  F|   1|\n",
      "|1993|Adelaide|  F|   1|\n",
      "+----+--------+---+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c048c-ece3-4c8e-b2b3-69f569182b0c",
   "metadata": {},
   "source": [
    "**Instead of calling a DataFrame _(df)_, once the table is built within PySpark, we can call it by name as well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ef8ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         | newborns|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1)\n",
    "spark.sql( \"SHOW TABLES\" ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f289180-a44e-4be9-a2a9-5a1587f23cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+----+\n",
      "|year|    name|sex|freq|\n",
      "+----+--------+---+----+\n",
      "|1993|  Abarna|  F|   1|\n",
      "|1993| Abetare|  F|   1|\n",
      "|1993|    Abir|  F|   1|\n",
      "|1993| Abirami|  F|   1|\n",
      "|1993|Adelaide|  F|   1|\n",
      "+----+--------+---+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2)\n",
    "spark.table( 'newborns' ).show(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41523df-0370-45b1-8d7b-3cc2b8ea22ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Aggregations(AGG): Calculating the overall newborn count in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "448725f7-b38b-411f-8e9a-1227a5ff45df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|overall_newborn_count|\n",
      "+---------------------+\n",
      "|               128164|\n",
      "+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "'''\n",
    "SELECT\n",
    "    SUM(freq) AS overall_newborn_count\n",
    "FROM \n",
    "    newborns\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f5ee56-1d57-4039-93ab-68191d3b33ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|sum(freq)|\n",
      "+---------+\n",
      "|   128164|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg( {'freq': 'sum'} ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833002d3-b30b-4f8c-9f8e-7d47ef2012f9",
   "metadata": {},
   "source": [
    "**Below solution â¬‡ï¸ provides _alias_, the same as \"AS\" in SQL.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30429b2a-5e88-47d9-8b7f-584b3b67f213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|overall_newborn_count|\n",
      "+---------------------+\n",
      "|               128164|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df.agg( sum('freq').alias('overall_newborn_count') ) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedcfd24-1461-4698-8508-6af40bbe0c79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## AGG: Analysis of the _year_ data value in the overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "368d234d-c60e-42fd-898c-34ca28b6b50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+\n",
      "|num_years|min_year|max_year|\n",
      "+---------+--------+--------+\n",
      "|       30|    1993|    2022|\n",
      "+---------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "'''\n",
    "SELECT\n",
    "    COUNT(DISTINCT year) num_years,\n",
    "    MIN(year) min_year,\n",
    "    MAX(year) max_year\n",
    "FROM \n",
    "    newborns\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11352ba0-540a-4df2-8f61-b0c0512766be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+\n",
      "|num_years|min_year|max_year|\n",
      "+---------+--------+--------+\n",
      "|       30|    1993|    2022|\n",
      "+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import min\n",
    "\n",
    "spark.table( 'newborns' ).agg(\n",
    "    countDistinct( 'year' ).alias( 'num_years' ),\n",
    "    min( 'year' ).alias( 'min_year' ),\n",
    "    max( 'year' ).alias( 'max_year' )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684b882-4bfc-4320-8b1b-6580304c883c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## AGG + Sort: Newborn count, based on distinct (grouped) years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30f025c2-98c5-47cb-8f59-a7451c28a423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2018, newborn_count=5212),\n",
       " Row(year=2019, newborn_count=5134),\n",
       " Row(year=2020, newborn_count=5133),\n",
       " Row(year=2021, newborn_count=5261),\n",
       " Row(year=2022, newborn_count=4538)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "'''\n",
    "SELECT\n",
    "    year,\n",
    "    SUM(freq) AS newborn_count\n",
    "FROM \n",
    "    newborns\n",
    "GROUP BY\n",
    "    year\n",
    "ORDER BY\n",
    "    year ASC\n",
    "'''\n",
    ").tail(5)\n",
    "# this time the final 5 rows of the overall query result is shown via \"tail\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5012a51e-c4a4-4500-adec-ddc558644a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2018, newborn_count=5212),\n",
       " Row(year=2019, newborn_count=5134),\n",
       " Row(year=2020, newborn_count=5133),\n",
       " Row(year=2021, newborn_count=5261),\n",
       " Row(year=2022, newborn_count=4538)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df.groupBy( 'year' ) \\\n",
    "    .agg( sum( 'freq' ).alias( 'newborn_count' ) ) \\\n",
    "    .sort( asc( 'year' ) ) \\\n",
    "    .tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704cb7b-c874-4637-ab28-8281fde206c6",
   "metadata": {},
   "source": [
    "ðŸ”¸ **_tail_ function needs to be used cautiously. As it brings the data to the memory, it might cause overflow.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f311fa4-51ea-4e72-965d-626f000c3bb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## AGG + OrderBy: Most popular newborn names over the years in Zurich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34f125c8-8722-478c-b4c4-0bf448f06e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| name|freq_count|\n",
      "+-----+----------+\n",
      "| Anna|       606|\n",
      "|David|       599|\n",
      "|Laura|       494|\n",
      "| Noah|       470|\n",
      "| Sara|       460|\n",
      "+-----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "'''\n",
    "SELECT \n",
    "    name,\n",
    "    SUM(freq) AS freq_count\n",
    "FROM\n",
    "    newborns\n",
    "GROUP BY\n",
    "    name\n",
    "ORDER BY\n",
    "    freq_count DESC\n",
    "LIMIT 5\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdf357c1-fc3d-489c-a98b-fd075fede48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| name|freq_count|\n",
      "+-----+----------+\n",
      "| Anna|       606|\n",
      "|David|       599|\n",
      "|Laura|       494|\n",
      "| Noah|       470|\n",
      "| Sara|       460|\n",
      "+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df.groupBy( 'name' ) \\\n",
    "    .agg( sum('freq').alias('freq_count') ) \\\n",
    "    .orderBy( desc('freq_count') ) \\\n",
    "    .show(5)\n",
    "# sort and orderBy do the same job for this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65fb2fe-6cfa-425e-a9b0-844cc61a53bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Union: The most popular male and female newborn names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15e67f34-2f6c-4e06-a0c8-0086083c1619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:>                 (0 + 1) / 1][Stage 53:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| name|sex|freq_count|\n",
      "+-----+---+----------+\n",
      "|David|  M|       599|\n",
      "| Anna|  F|       606|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_names = \\\n",
    "'''\n",
    "(\n",
    "    SELECT\n",
    "        name,\n",
    "        sex,\n",
    "        SUM(freq) AS freq_count\n",
    "    FROM\n",
    "        newborns\n",
    "    WHERE \n",
    "        sex = '{}'\n",
    "    GROUP BY\n",
    "        name, sex\n",
    "    ORDER BY\n",
    "        freq_count DESC\n",
    "    LIMIT 1\n",
    ")\n",
    "'''\n",
    "\n",
    "spark.sql(\n",
    "    df_names.format('M') + 'UNION' + df_names.format('F')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c45bb7f-8f08-44f7-a82e-6a7f88e14a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:>                 (0 + 1) / 1][Stage 62:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| name|sex|freq_count|\n",
      "+-----+---+----------+\n",
      "|David|  M|       599|\n",
      "| Anna|  F|       606|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df_male = df.filter( df.sex == 'M' ) \\\n",
    "                .groupBy( ['name', 'sex'] ) \\\n",
    "                .agg( sum('freq').alias('freq_count') ) \\\n",
    "                .orderBy( desc('freq_count') ).limit(1)\n",
    "\n",
    "# this 'groupBy' syntax also works the same as above.\n",
    "df_female = df.filter( df.sex == 'F' ) \\\n",
    "                .groupBy( 'name', 'sex' ) \\\n",
    "                .agg( sum('freq').alias('freq_count') ) \\\n",
    "                .orderBy( desc('freq_count') ).limit(1)\n",
    "\n",
    "df_male.union( df_female ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db16aca-3da1-468e-b301-e675ff189d9c",
   "metadata": {},
   "source": [
    "These names can be seen in the previous part, among the _most popular baby names_ as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7acc7f-bf8b-49cf-97c8-248c69975f80",
   "metadata": {},
   "source": [
    "## AGG + Filtering + Subquery: Top 3 most popular female names in recent times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218dbca-830a-4fef-9829-4f81b1c9f46c",
   "metadata": {},
   "source": [
    "_Recent times = Max. year in the data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a86fd96-8ff9-40ff-bf3c-12458f507dad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|name|freq|\n",
      "+----+----+\n",
      "|Anna|  21|\n",
      "|Nora|  18|\n",
      "|Ella|  17|\n",
      "+----+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "'''\n",
    "SELECT\n",
    "    name, freq\n",
    "FROM \n",
    "    newborns\n",
    "WHERE \n",
    "    sex = 'F' AND year = ( SELECT MAX(year) from newborns )\n",
    "ORDER BY\n",
    "    freq DESC\n",
    "LIMIT 3'''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a82e239d-5e6f-40a5-982b-22833d272066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|name|freq|\n",
      "+----+----+\n",
      "|Anna|  21|\n",
      "|Nora|  18|\n",
      "|Ella|  17|\n",
      "+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# instead of \"head()[0]\", \"collect()[0][0]\" can also be used below.\n",
    "max_year = df.agg( {'year': 'max'} ).head()[0]\n",
    "\n",
    "# \"where\" and \"filter\" can be used interchangeably below.\n",
    "df.where( (df.sex == 'F') & (df.year == max_year) ) \\\n",
    "    .select( 'name', 'freq' ) \\\n",
    "    .orderBy( desc('freq') ) \\\n",
    "    .show(3)\n",
    "# If you end it with \"limit\" instead of \"show\" right above, it doesn't show the records;\n",
    "# just returns a DataFrame object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e953801-bfc3-4c24-9325-0167c3f0df8f",
   "metadata": {},
   "source": [
    "**The same result was also shared in the [statistics page](https://www.stadt-zuerich.ch/content/prd/de/index/statistik/themen/bevoelkerung/geburten-kinder-vornamen/vornamen.html) of the city of Zurich as showcased below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de0091a7-a3f3-4d99-a482-57255488834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/top_female_names.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import image module\n",
    "from IPython.display import Image\n",
    "# get the image\n",
    "Image( url=\"img/top_female_names.png\", width=500 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newborns_spark",
   "language": "python",
   "name": "newborns_spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
